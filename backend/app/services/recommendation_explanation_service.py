"""ì¶”ì²œ ì´ìœ  ì„¤ëª… ìƒì„± ì„œë¹„ìŠ¤ (RAG ê¸°ë°˜)"""
import logging
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from app.utils.openai_client import get_openai_client
from app.core.config import settings

logger = logging.getLogger(__name__)

# Chroma Vector Store ì‚¬ìš©
try:
    import chromadb
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False
    logger.warning("chromadbê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RAG ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install chromadb' ì‹¤í–‰ í•„ìš”")

# TODO: RAG êµ¬í˜„ (v1.1.0)
# 1. Vector Store êµ¬ì¶•
#    - Veterinary Allergy 4th Edition ì„ë² ë”©
#    - FEDIAF 2025 Nutritional Guidelines ì„ë² ë”©
#    - AAFCO 2025 Official Publication ì„ë² ë”©
#    - Small Animal Clinical Nutrition (5th Edition) ì„ë² ë”©
# 2. Retrieval íŒŒì´í”„ë¼ì¸
#    - í« í”„ë¡œí•„ + ìƒí’ˆ ì •ë³´ë¥¼ ì¿¼ë¦¬ë¡œ ë³€í™˜
#    - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ Top 5 ê´€ë ¨ ì²­í¬ ì¶”ì¶œ
#    - ê° ì²­í¬ì— ì¶œì²˜ ë©”íƒ€ë°ì´í„° í¬í•¨
# 3. Confidence Score ê³„ì‚°
#    - LLM ì‘ë‹µì˜ ì‹ ë¢°ë„ ì ìˆ˜ (0~100)
#    - 75ì  ë¯¸ë§Œ ì‹œ fallback ë©”ì‹œì§€ ì‚¬ìš©

SYSTEM_PROMPT_TECHNICAL = """ë„ˆëŠ” ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì„¤ëª… ìƒì„±ê¸°ë‹¤.
ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ ê³¼ì •ì„ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜.
í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜.
ì„¤ëª…ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì¤˜:
1. í«ì˜ íŠ¹ì„±(ë‚˜ì´, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì 
2. ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ ìƒí’ˆì„ ì„ íƒí•œ ì´ìœ 
3. êµ¬ì²´ì ì¸ í˜œíƒì´ë‚˜ íš¨ê³¼"""

SYSTEM_PROMPT_EXPERT = """ë„ˆëŠ” ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ ì¶”ì²œ ì „ë¬¸ê°€ë‹¤.
ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ ì´ìœ ë¥¼ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜.
í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜.
ì„¤ëª…ì€ 3-5ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì¤˜:
1. í«ì˜ íŠ¹ì„±(ë‚˜ì´, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì 
2. ì£¼ìš” ì„±ë¶„ì´ë‚˜ íŠ¹ì§•ì´ í«ì—ê²Œ ì™œ ì¢‹ì€ì§€
3. ì°¸ê³  ìë£Œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ê·¼ê±°ë¡œ í•œ ì „ë¬¸ì ì¸ ì„¤ëª…
4. êµ¬ì²´ì ì¸ í˜œíƒì´ë‚˜ íš¨ê³¼"""

USER_PROMPT_TEMPLATE_TECHNICAL = """í« ì •ë³´:
- ì´ë¦„: {pet_name}
- ì¢…ë¥˜: {pet_species}
- ë‚˜ì´ ë‹¨ê³„: {pet_age_stage}
- ì²´ì¤‘: {pet_weight}kg
- í’ˆì¢…: {pet_breed}
- ì¤‘ì„±í™”: {pet_neutered}
- ê±´ê°• ê³ ë¯¼: {health_concerns}
- ì•Œë ˆë¥´ê¸°: {allergies}

ì¶”ì²œ ìƒí’ˆ:
- ë¸Œëœë“œ: {brand_name}
- ìƒí’ˆëª…: {product_name}

ì¶”ì²œ ì´ìœ  (ê¸°ìˆ ì ):
{technical_reasons}

ì‚¬ìš©ì ì„ í˜¸ë„:
{user_prefs_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ ì‚¬ë£Œë¥¼ ì™œ ì„ íƒí–ˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜.

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì„œ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜:
1. í«ì˜ ì´ë¦„ì„ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ ì‹œì‘
2. í«ì˜ íŠ¹ì„±(ë‚˜ì´ ë‹¨ê³„, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ ìƒí’ˆì„ ì„ íƒí•œ ê¸°ìˆ ì  ì´ìœ ë¥¼ ì„¤ëª…
4. ì‚¬ìš©ì ì„ í˜¸ë„ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰

ì„¤ëª…ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜."""

USER_PROMPT_TEMPLATE_EXPERT = """í« ì •ë³´:
- ì´ë¦„: {pet_name}
- ì¢…ë¥˜: {pet_species}
- ë‚˜ì´ ë‹¨ê³„: {pet_age_stage}
- ì²´ì¤‘: {pet_weight}kg
- í’ˆì¢…: {pet_breed}
- ì¤‘ì„±í™”: {pet_neutered}
- ê±´ê°• ê³ ë¯¼: {health_concerns}
- ì•Œë ˆë¥´ê¸°: {allergies}

ì¶”ì²œ ìƒí’ˆ:
- ë¸Œëœë“œ: {brand_name}
- ìƒí’ˆëª…: {product_name}

ì¶”ì²œ ì´ìœ  (ê¸°ìˆ ì ):
{technical_reasons}

ì‚¬ìš©ì ì„ í˜¸ë„:
{user_prefs_text}

{rag_context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ ì‚¬ë£Œê°€ ì™œ ì´ í«ì—ê²Œ ì¶”ì²œë˜ëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê³  ì¹œì ˆí•˜ê²Œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜.

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì„œ 3-5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜:
1. í«ì˜ ì´ë¦„ì„ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ ì‹œì‘
2. í«ì˜ íŠ¹ì„±(ë‚˜ì´ ë‹¨ê³„, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ì£¼ìš” ì„±ë¶„ì´ë‚˜ íŠ¹ì§•ì´ í«ì—ê²Œ ì–´ë–¤ í˜œíƒì„ ì£¼ëŠ”ì§€ ìƒì„¸íˆ ì„¤ëª…
4. ì°¸ê³  ìë£Œ(rag_context)ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ê·¼ê±°ë¡œ ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„¤ëª… ì¶”ê°€
5. ì‚¬ìš©ì ì„ í˜¸ë„ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰

ì„¤ëª…ì€ êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜."""


class RecommendationExplanationService:
    """ì¶”ì²œ ì´ìœ  ì„¤ëª… ìƒì„± ì„œë¹„ìŠ¤ (RAG ê¸°ë°˜)"""
    
    @staticmethod
    async def _retrieve_relevant_chunks(
        pet_species: str,
        health_concerns: List[str],
        allergies: List[str],
        product_name: str,
        top_k: int = 5
    ) -> List[Dict]:
        """
        Vector Storeì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰
        
        Returns:
            List[Dict]: ê° ì²­í¬ëŠ” {'content': str, 'source': str, 'metadata': dict} í˜•íƒœ
        """
        if not CHROMA_AVAILABLE:
            logger.debug("[RAG] ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ RAG ê²€ìƒ‰ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return []
        
        try:
            # Vector Store ê²½ë¡œ
            project_root = Path(__file__).parent.parent.parent
            vector_store_path = project_root / "data" / "vector_store"
            
            if not vector_store_path.exists():
                logger.debug(f"[RAG] Vector Storeê°€ ì—†ìŠµë‹ˆë‹¤: {vector_store_path}")
                return []
            
            # Chroma í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = chromadb.PersistentClient(path=str(vector_store_path))
            
            # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
            try:
                collection = client.get_collection(name="pet_food_rag")
            except Exception as e:
                logger.debug(f"[RAG] ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                return []
            
            # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
            query_parts = []
            if pet_species:
                query_parts.append(f"{pet_species} ì‚¬ë£Œ")
            if health_concerns:
                query_parts.extend(health_concerns)
            if allergies:
                query_parts.extend([f"{allergy} ì•Œë ˆë¥´ê¸°" for allergy in allergies])
            if product_name:
                query_parts.append(product_name)
            
            query_text = " ".join(query_parts) if query_parts else product_name or "ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ"
            
            logger.debug(f"[RAG] ì¿¼ë¦¬: {query_text}")
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            openai_client = get_openai_client()
            query_response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=query_text
            )
            query_embedding = query_response.data[0].embedding
            
            # Vector Storeì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=["documents", "metadatas", "distances"]
            )
            
            # ê²°ê³¼ ë³€í™˜
            chunks = []
            if results["ids"] and len(results["ids"][0]) > 0:
                for idx, doc_id in enumerate(results["ids"][0]):
                    chunk = {
                        "content": results["documents"][0][idx],
                        "source": results["metadatas"][0][idx].get("source", "Unknown"),
                        "file": results["metadatas"][0][idx].get("file", "Unknown"),
                        "distance": results["distances"][0][idx],
                        "metadata": results["metadatas"][0][idx]
                    }
                    chunks.append(chunk)
                
                logger.info(f"[RAG] âœ… {len(chunks)}ê°œ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ")
                
                # RAG ë°˜í™˜ê°’ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
                logger.info("=" * 80)
                logger.info("[RAG] ğŸ“‹ RAG ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸:")
                logger.info("=" * 80)
                for idx, chunk in enumerate(chunks, 1):
                    logger.info(f"\n[ì²­í¬ {idx}/{len(chunks)}]")
                    logger.info(f"  ğŸ“„ ì¶œì²˜ (Source): {chunk.get('source', 'Unknown')}")
                    logger.info(f"  ğŸ“ íŒŒì¼ (File): {chunk.get('file', 'Unknown')}")
                    logger.info(f"  ğŸ“ ìœ ì‚¬ë„ ê±°ë¦¬ (Distance): {chunk.get('distance', 0.0):.4f}")
                    logger.info(f"  ğŸ“ ë‚´ìš© (Content): {chunk.get('content', '')[:200]}...")  # ì²˜ìŒ 200ìë§Œ
                    logger.info(f"  ğŸ·ï¸  ë©”íƒ€ë°ì´í„°: {chunk.get('metadata', {})}")
                logger.info("=" * 80)
            else:
                logger.warning("[RAG] âš ï¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            return chunks
            
        except Exception as e:
            logger.error(f"[RAG] ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            return []
    
    @staticmethod
    def _calculate_confidence_score(
        explanation: str,
        retrieved_chunks: List[Dict],
        llm_response_metadata: Optional[Dict] = None
    ) -> float:
        """
        RAG ê¸°ë°˜ ì„¤ëª…ì˜ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0~100)
        
        Args:
            explanation: ìƒì„±ëœ ì„¤ëª…
            retrieved_chunks: ê²€ìƒ‰ëœ ë¬¸ì„œ ì²­í¬
            llm_response_metadata: LLM ì‘ë‹µ ë©”íƒ€ë°ì´í„° (logprobs ë“±)
        
        Returns:
            float: ì‹ ë¢°ë„ ì ìˆ˜ (0~100)
        """
        if not explanation:
            return 0.0
        
        # RAG ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë‚®ì€ ì‹ ë¢°ë„
        if not retrieved_chunks:
            return 50.0
        
        # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        # Chromaì˜ distanceëŠ” ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
        # distanceë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜: distanceê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
        distances = [chunk.get("distance", 1.0) for chunk in retrieved_chunks]
        avg_distance = sum(distances) / len(distances) if distances else 1.0
        
        # distanceë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜ (0.0 ~ 1.0 ë²”ìœ„ë¥¼ 50 ~ 100 ì ìˆ˜ë¡œ ë³€í™˜)
        # distanceê°€ 0.5 ì´í•˜ë©´ ë†’ì€ ì‹ ë¢°ë„ (80~100)
        # distanceê°€ 0.5~1.0ì´ë©´ ì¤‘ê°„ ì‹ ë¢°ë„ (60~80)
        # distanceê°€ 1.0 ì´ìƒì´ë©´ ë‚®ì€ ì‹ ë¢°ë„ (50~60)
        if avg_distance <= 0.5:
            confidence = 80.0 + (0.5 - avg_distance) * 40.0  # 80~100
        elif avg_distance <= 1.0:
            confidence = 60.0 + (1.0 - avg_distance) * 40.0  # 60~80
        else:
            confidence = 50.0 + max(0, 10.0 - (avg_distance - 1.0) * 10.0)  # 50~60
        
        return min(100.0, max(0.0, confidence))
    
    @staticmethod
    async def generate_technical_explanation(
        pet_name: str,
        pet_species: str,
        pet_age_stage: Optional[str],
        pet_weight: float,
        pet_breed: Optional[str],
        pet_neutered: Optional[bool],
        health_concerns: List[str],
        allergies: List[str],
        brand_name: str,
        product_name: str,
        technical_reasons: List[str],
        user_prefs: dict = None
    ) -> str:
        """
        ê¸°ìˆ ì  ì¶”ì²œ ì´ìœ  ê¸°ë°˜ ì„¤ëª… ìƒì„± (RAG ì—†ìŒ, ë¹ ë¦„)
        
        Args:
            pet_name: í« ì´ë¦„
            pet_species: í« ì¢…ë¥˜ (DOG/CAT)
            pet_age_stage: ë‚˜ì´ ë‹¨ê³„ (PUPPY/ADULT/SENIOR)
            pet_weight: ì²´ì¤‘ (kg)
            pet_breed: í’ˆì¢… ì½”ë“œ
            pet_neutered: ì¤‘ì„±í™” ì—¬ë¶€
            health_concerns: ê±´ê°• ê³ ë¯¼ ë¦¬ìŠ¤íŠ¸
            allergies: ì•Œë ˆë¥´ê¸° ë¦¬ìŠ¤íŠ¸
            brand_name: ë¸Œëœë“œëª…
            product_name: ìƒí’ˆëª…
            technical_reasons: ê¸°ìˆ ì  ì¶”ì²œ ì´ìœ  ë¦¬ìŠ¤íŠ¸
            user_prefs: ì‚¬ìš©ì ì„ í˜¸ë„
        
        Returns:
            ìì—°ì–´ ì„¤ëª… ë¬¸ìì—´
        """
        try:
            logger.info(f"[Explanation Service] ğŸ”§ ê¸°ìˆ ì  ì„¤ëª… ìƒì„± ì‹œì‘: {pet_name} - {brand_name} {product_name}")
            
            # ê¸°ìˆ ì  ì´ìœ ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            reasons_text = "\n".join([f"- {reason}" for reason in technical_reasons])
            
            # ë‚˜ì´ ë‹¨ê³„ í•œê¸€ ë³€í™˜
            age_stage_kr = {
                "PUPPY": "ê°•ì•„ì§€",
                "ADULT": "ì„±ê²¬",
                "SENIOR": "ë…¸ê²¬"
            }.get(pet_age_stage or "", "ì„±ê²¬")
            
            # ì¢…ë¥˜ í•œê¸€ ë³€í™˜
            species_kr = "ê°•ì•„ì§€" if pet_species == "DOG" else "ê³ ì–‘ì´"
            
            # ì¤‘ì„±í™” ì—¬ë¶€ í…ìŠ¤íŠ¸
            neutered_text = "ì™„ë£Œ" if pet_neutered else "ë¯¸ì™„ë£Œ" if pet_neutered is False else "ëª¨ë¦„"
            
            # ê±´ê°• ê³ ë¯¼ í…ìŠ¤íŠ¸
            health_concerns_text = ", ".join(health_concerns) if health_concerns else "ì—†ìŒ"
            
            # ì•Œë ˆë¥´ê¸° í…ìŠ¤íŠ¸
            allergies_text = ", ".join(allergies) if allergies else "ì—†ìŒ"
            
            # í’ˆì¢… í…ìŠ¤íŠ¸
            breed_text = pet_breed or "ì •ë³´ ì—†ìŒ"
            
            # ì‚¬ìš©ì ì„ í˜¸ë„ í…ìŠ¤íŠ¸ ìƒì„±
            user_prefs_text = "ì—†ìŒ"
            if user_prefs:
                weights_preset = user_prefs.get("weights_preset", "BALANCED")
                hard_exclude = user_prefs.get("hard_exclude_allergens", [])
                soft_avoid = user_prefs.get("soft_avoid_ingredients", [])
                max_price = user_prefs.get("max_price_per_kg")
                
                preset_kr = {
                    "SAFE": "ì•ˆì „ ìš°ì„ ",
                    "BALANCED": "ê· í˜•",
                    "VALUE": "ê°€ì„±ë¹„ ìš°ì„ "
                }.get(weights_preset, weights_preset)
                
                prefs_parts = [f"ëª¨ë“œ: {preset_kr}"]
                if hard_exclude:
                    prefs_parts.append(f"ì œì™¸ ì•Œë ˆë¥´ê²: {', '.join(hard_exclude)}")
                if soft_avoid:
                    prefs_parts.append(f"í”¼í•˜ê³  ì‹¶ì€ ì„±ë¶„: {', '.join(soft_avoid)}")
                if max_price:
                    prefs_parts.append(f"ìµœëŒ€ ê°€ê²©: {max_price}ì›/kg")
                
                user_prefs_text = ", ".join(prefs_parts) if prefs_parts else "ì—†ìŒ"
            
            prompt = USER_PROMPT_TEMPLATE_TECHNICAL.format(
                pet_name=pet_name,
                pet_species=species_kr,
                pet_age_stage=age_stage_kr,
                pet_weight=pet_weight,
                pet_breed=breed_text,
                pet_neutered=neutered_text,
                health_concerns=health_concerns_text,
                allergies=allergies_text,
                brand_name=brand_name,
                product_name=product_name,
                technical_reasons=reasons_text,
                user_prefs_text=user_prefs_text
            )
            
            client = get_openai_client()
            
            response = client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                temperature=0.7,
                max_tokens=250,  # ê¸°ìˆ ì  ì„¤ëª…ì€ ë” ì§§ê²Œ
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_TECHNICAL},
                    {"role": "user", "content": prompt},
                ],
            )
            
            explanation = response.choices[0].message.content.strip()
            logger.info(f"[Explanation Service] âœ… ê¸°ìˆ ì  ì„¤ëª… ìƒì„± ì™„ë£Œ: {explanation[:50]}...")
            
            return explanation
            
        except Exception as e:
            logger.error(f"[Explanation Service] ê¸°ìˆ ì  ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª… ë°˜í™˜
            return RecommendationExplanationService._generate_fallback_explanation(
                pet_name, technical_reasons
            )
    
    @staticmethod
    async def generate_expert_explanation(
        pet_name: str,
        pet_species: str,
        pet_age_stage: Optional[str],
        pet_weight: float,
        pet_breed: Optional[str],
        pet_neutered: Optional[bool],
        health_concerns: List[str],
        allergies: List[str],
        brand_name: str,
        product_name: str,
        technical_reasons: List[str],
        user_prefs: dict = None
    ) -> str:
        """
        RAG ê¸°ë°˜ ì „ë¬¸ê°€ ìˆ˜ì¤€ ì„¤ëª… ìƒì„± (ëŠë¦¼)
        
        Args:
            pet_name: í« ì´ë¦„
            pet_species: í« ì¢…ë¥˜ (DOG/CAT)
            pet_age_stage: ë‚˜ì´ ë‹¨ê³„ (PUPPY/ADULT/SENIOR)
            pet_weight: ì²´ì¤‘ (kg)
            pet_breed: í’ˆì¢… ì½”ë“œ
            pet_neutered: ì¤‘ì„±í™” ì—¬ë¶€
            health_concerns: ê±´ê°• ê³ ë¯¼ ë¦¬ìŠ¤íŠ¸
            allergies: ì•Œë ˆë¥´ê¸° ë¦¬ìŠ¤íŠ¸
            brand_name: ë¸Œëœë“œëª…
            product_name: ìƒí’ˆëª…
            technical_reasons: ê¸°ìˆ ì  ì¶”ì²œ ì´ìœ  ë¦¬ìŠ¤íŠ¸
            user_prefs: ì‚¬ìš©ì ì„ í˜¸ë„
        
        Returns:
            ìì—°ì–´ ì„¤ëª… ë¬¸ìì—´
        """
        try:
            # RAG: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            logger.info("=" * 80)
            logger.info(f"[RAG] ğŸ¯ RAG ì‹¤í–‰ ì‹œì‘: pet_species={pet_species}, product={product_name}")
            logger.info(f"[RAG] ğŸ“‹ ì…ë ¥ íŒŒë¼ë¯¸í„°: health_concerns={health_concerns}, allergies={allergies}")
            logger.info("=" * 80)
            retrieved_chunks = await RecommendationExplanationService._retrieve_relevant_chunks(
                pet_species=pet_species,
                health_concerns=health_concerns,
                allergies=allergies,
                product_name=product_name,
                top_k=5
            )
            logger.info(f"[RAG] âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(retrieved_chunks)}ê°œ ë¬¸ì„œ ì²­í¬ ë°œê²¬")
            
            # RAG ë°˜í™˜ê°’ ì „ì²´ ë¡œê·¸ ì¶œë ¥
            if retrieved_chunks:
                logger.info("\n" + "=" * 80)
                logger.info("[RAG] ğŸ“Š ì „ë¬¸ê°€ ì„¤ëª… ìƒì„±ì—ì„œ ë°›ì€ RAG ê²°ê³¼ ìš”ì•½:")
                logger.info("=" * 80)
                for idx, chunk in enumerate(retrieved_chunks, 1):
                    logger.info(f"\n[ì²­í¬ {idx}/{len(retrieved_chunks)}]")
                    logger.info(f"  ì¶œì²˜: {chunk.get('source', 'Unknown')}")
                    logger.info(f"  íŒŒì¼: {chunk.get('file', 'Unknown')}")
                    logger.info(f"  ê±°ë¦¬: {chunk.get('distance', 0.0):.4f}")
                    logger.info(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {chunk.get('content', '')[:150]}...")
                logger.info("=" * 80 + "\n")
            
            # RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            rag_context = ""
            if retrieved_chunks:
                rag_context = "\nì°¸ê³  ìë£Œ (ì „ë¬¸ ë¬¸ì„œ):\n"
                for idx, chunk in enumerate(retrieved_chunks[:5], 1):
                    source = chunk.get("source", "Unknown")
                    content = chunk.get("content", "")[:500]
                    distance = chunk.get("distance", 0.0)
                    rag_context += f"{idx}. [{source}] (ìœ ì‚¬ë„: {1-distance:.2f})\n{content}\n\n"
            else:
                rag_context = "\nì°¸ê³  ìë£Œ: ì—†ìŒ\n"
            
            # ê¸°ìˆ ì  ì´ìœ ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            reasons_text = "\n".join([f"- {reason}" for reason in technical_reasons])
            
            # ë‚˜ì´ ë‹¨ê³„ í•œê¸€ ë³€í™˜
            age_stage_kr = {
                "PUPPY": "ê°•ì•„ì§€",
                "ADULT": "ì„±ê²¬",
                "SENIOR": "ë…¸ê²¬"
            }.get(pet_age_stage or "", "ì„±ê²¬")
            
            # ì¢…ë¥˜ í•œê¸€ ë³€í™˜
            species_kr = "ê°•ì•„ì§€" if pet_species == "DOG" else "ê³ ì–‘ì´"
            
            # ì¤‘ì„±í™” ì—¬ë¶€ í…ìŠ¤íŠ¸
            neutered_text = "ì™„ë£Œ" if pet_neutered else "ë¯¸ì™„ë£Œ" if pet_neutered is False else "ëª¨ë¦„"
            
            # ê±´ê°• ê³ ë¯¼ í…ìŠ¤íŠ¸
            health_concerns_text = ", ".join(health_concerns) if health_concerns else "ì—†ìŒ"
            
            # ì•Œë ˆë¥´ê¸° í…ìŠ¤íŠ¸
            allergies_text = ", ".join(allergies) if allergies else "ì—†ìŒ"
            
            # í’ˆì¢… í…ìŠ¤íŠ¸
            breed_text = pet_breed or "ì •ë³´ ì—†ìŒ"
            
            # ì‚¬ìš©ì ì„ í˜¸ë„ í…ìŠ¤íŠ¸ ìƒì„±
            user_prefs_text = "ì—†ìŒ"
            if user_prefs:
                weights_preset = user_prefs.get("weights_preset", "BALANCED")
                hard_exclude = user_prefs.get("hard_exclude_allergens", [])
                soft_avoid = user_prefs.get("soft_avoid_ingredients", [])
                max_price = user_prefs.get("max_price_per_kg")
                
                preset_kr = {
                    "SAFE": "ì•ˆì „ ìš°ì„ ",
                    "BALANCED": "ê· í˜•",
                    "VALUE": "ê°€ì„±ë¹„ ìš°ì„ "
                }.get(weights_preset, weights_preset)
                
                prefs_parts = [f"ëª¨ë“œ: {preset_kr}"]
                if hard_exclude:
                    prefs_parts.append(f"ì œì™¸ ì•Œë ˆë¥´ê²: {', '.join(hard_exclude)}")
                if soft_avoid:
                    prefs_parts.append(f"í”¼í•˜ê³  ì‹¶ì€ ì„±ë¶„: {', '.join(soft_avoid)}")
                if max_price:
                    prefs_parts.append(f"ìµœëŒ€ ê°€ê²©: {max_price}ì›/kg")
                
                user_prefs_text = ", ".join(prefs_parts) if prefs_parts else "ì—†ìŒ"
            
            prompt = USER_PROMPT_TEMPLATE_EXPERT.format(
                pet_name=pet_name,
                pet_species=species_kr,
                pet_age_stage=age_stage_kr,
                pet_weight=pet_weight,
                pet_breed=breed_text,
                pet_neutered=neutered_text,
                health_concerns=health_concerns_text,
                allergies=allergies_text,
                brand_name=brand_name,
                product_name=product_name,
                technical_reasons=reasons_text,
                user_prefs_text=user_prefs_text,
                rag_context=rag_context
            )
            
            client = get_openai_client()
            
            logger.info(f"[Explanation Service] ğŸ“ ì „ë¬¸ê°€ ì„¤ëª… ìƒì„± ì‹œì‘: {pet_name} - {brand_name} {product_name}")
            
            response = client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                temperature=0.7,
                max_tokens=400,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_EXPERT},
                    {"role": "user", "content": prompt},
                ],
            )
            
            explanation = response.choices[0].message.content.strip()
            
            # Confidence Score ê³„ì‚°
            confidence_score = RecommendationExplanationService._calculate_confidence_score(
                explanation=explanation,
                retrieved_chunks=retrieved_chunks
            )
            
            logger.info(f"[Explanation Service] âœ… ì „ë¬¸ê°€ ì„¤ëª… ìƒì„± ì™„ë£Œ: {explanation[:50]}... (ì‹ ë¢°ë„: {confidence_score:.1f}ì )")
            
            # ì‹ ë¢°ë„ê°€ 75ì  ë¯¸ë§Œì´ë©´ fallback ë©”ì‹œì§€ ì‚¬ìš©
            if confidence_score < 75.0:
                logger.warning(f"[Explanation Service] ì‹ ë¢°ë„ê°€ ë‚®ì•„ fallback ë©”ì‹œì§€ ì‚¬ìš©: {confidence_score:.1f}ì ")
                return RecommendationExplanationService._generate_fallback_explanation(
                    pet_name, technical_reasons
                )
            
            return explanation
            
        except Exception as e:
            logger.error(f"[Explanation Service] ì „ë¬¸ê°€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª… ë°˜í™˜
            return RecommendationExplanationService._generate_fallback_explanation(
                pet_name, technical_reasons
            )
    
    @staticmethod
    async def generate_explanation(
        pet_name: str,
        pet_species: str,
        pet_age_stage: Optional[str],
        pet_weight: float,
        pet_breed: Optional[str],
        pet_neutered: Optional[bool],
        health_concerns: List[str],
        allergies: List[str],
        brand_name: str,
        product_name: str,
        technical_reasons: List[str],
        user_prefs: dict = None
    ) -> str:
        """
        [Deprecated] í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
        ì „ë¬¸ê°€ ì„¤ëª…(expert_explanation)ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        logger.warning("[Explanation Service] generate_explanationì€ deprecatedì…ë‹ˆë‹¤. generate_expert_explanationì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return await RecommendationExplanationService.generate_expert_explanation(
            pet_name=pet_name,
            pet_species=pet_species,
            pet_age_stage=pet_age_stage,
            pet_weight=pet_weight,
            pet_breed=pet_breed,
            pet_neutered=pet_neutered,
            health_concerns=health_concerns,
            allergies=allergies,
            brand_name=brand_name,
            product_name=product_name,
            technical_reasons=technical_reasons,
            user_prefs=user_prefs
        )
    
    @staticmethod
    def _generate_fallback_explanation(pet_name: str, technical_reasons: List[str]) -> str:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª… ìƒì„±"""
        if not technical_reasons:
            return f"{pet_name}ì—ê²Œ ì í•©í•œ ì‚¬ë£Œì…ë‹ˆë‹¤."
        
        # ì£¼ìš” ì´ìœ ë§Œ ì„ íƒ (ìµœëŒ€ 3ê°œ)
        main_reasons = technical_reasons[:3]
        reasons_text = ", ".join(main_reasons)
        
        return f"{pet_name}ì—ê²Œ {reasons_text} ë“±ì˜ ì´ìœ ë¡œ ì¶”ì²œë˜ëŠ” ì‚¬ë£Œì…ë‹ˆë‹¤."

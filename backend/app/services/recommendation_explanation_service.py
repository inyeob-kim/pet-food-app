"""ì¶”ì²œ ì´ìœ  ì„¤ëª… ìƒì„± ì„œë¹„ìŠ¤ (RAG ê¸°ë°˜)"""
import logging
from pathlib import Path
from typing import List, Optional, Dict, Tuple
from app.utils.openai_client import get_openai_client
from app.core.config import settings

logger = logging.getLogger(__name__)

# Chroma Vector Store ì‚¬ìš©
try:
    import chromadb
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False
    logger.warning("chromadbê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RAG ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install chromadb' ì‹¤í–‰ í•„ìš”")

# TODO: RAG êµ¬í˜„ (v1.1.0)
# 1. Vector Store êµ¬ì¶•
#    - Veterinary Allergy 4th Edition ì„ë² ë”©
#    - FEDIAF 2025 Nutritional Guidelines ì„ë² ë”©
#    - AAFCO 2025 Official Publication ì„ë² ë”©
#    - Small Animal Clinical Nutrition (5th Edition) ì„ë² ë”©
# 2. Retrieval íŒŒì´í”„ë¼ì¸
#    - í« í”„ë¡œí•„ + ìƒí’ˆ ì •ë³´ë¥¼ ì¿¼ë¦¬ë¡œ ë³€í™˜
#    - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ Top 5 ê´€ë ¨ ì²­í¬ ì¶”ì¶œ
#    - ê° ì²­í¬ì— ì¶œì²˜ ë©”íƒ€ë°ì´í„° í¬í•¨
# 3. Confidence Score ê³„ì‚°
#    - LLM ì‘ë‹µì˜ ì‹ ë¢°ë„ ì ìˆ˜ (0~100)
#    - 75ì  ë¯¸ë§Œ ì‹œ fallback ë©”ì‹œì§€ ì‚¬ìš©

SYSTEM_PROMPT_TECHNICAL = """ë„ˆëŠ” ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì„¤ëª… ìƒì„±ê¸°ë‹¤.
ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ ê³¼ì •ì„ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜.
í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜.
ì„¤ëª…ì€ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì¤˜:
1. í«ì˜ íŠ¹ì„±(ë‚˜ì´, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì 
2. ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ ìƒí’ˆì„ ì„ íƒí•œ ì´ìœ 
3. êµ¬ì²´ì ì¸ í˜œíƒì´ë‚˜ íš¨ê³¼"""

SYSTEM_PROMPT_EXPERT = """ë„ˆëŠ” ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ ì¶”ì²œ ì „ë¬¸ê°€ë‹¤.
ì‚¬ìš©ìì—ê²Œ ì¶”ì²œ ì´ìœ ë¥¼ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜.
í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜.
ì„¤ëª…ì€ 3-5ë¬¸ì¥ìœ¼ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì¤˜:
1. í«ì˜ íŠ¹ì„±(ë‚˜ì´, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì 
2. ì£¼ìš” ì„±ë¶„ì´ë‚˜ íŠ¹ì§•ì´ í«ì—ê²Œ ì™œ ì¢‹ì€ì§€
3. ì°¸ê³  ìë£Œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ê·¼ê±°ë¡œ í•œ ì „ë¬¸ì ì¸ ì„¤ëª…
4. êµ¬ì²´ì ì¸ í˜œíƒì´ë‚˜ íš¨ê³¼"""

USER_PROMPT_TEMPLATE_TECHNICAL = """í« ì •ë³´:
- ì´ë¦„: {pet_name}
- ì¢…ë¥˜: {pet_species}
- ë‚˜ì´ ë‹¨ê³„: {pet_age_stage}
- ì²´ì¤‘: {pet_weight}kg
- í’ˆì¢…: {pet_breed}
- ì¤‘ì„±í™”: {pet_neutered}
- ê±´ê°• ê³ ë¯¼: {health_concerns}
- ì•Œë ˆë¥´ê¸°: {allergies}

ì¶”ì²œ ìƒí’ˆ:
- ë¸Œëœë“œ: {brand_name}
- ìƒí’ˆëª…: {product_name}

ì¶”ì²œ ì´ìœ  (ê¸°ìˆ ì ):
{technical_reasons}

ì‚¬ìš©ì ì„ í˜¸ë„:
{user_prefs_text}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ ì‚¬ë£Œë¥¼ ì™œ ì„ íƒí–ˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì¤˜.

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì„œ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜:
1. í«ì˜ ì´ë¦„ì„ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ ì‹œì‘
2. í«ì˜ íŠ¹ì„±(ë‚˜ì´ ë‹¨ê³„, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ì¶”ì²œ ì‹œìŠ¤í…œì´ ì´ ìƒí’ˆì„ ì„ íƒí•œ ê¸°ìˆ ì  ì´ìœ ë¥¼ ì„¤ëª…
4. ì‚¬ìš©ì ì„ í˜¸ë„ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰

ì„¤ëª…ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜."""

USER_PROMPT_TEMPLATE_EXPERT = """í« ì •ë³´:
- ì´ë¦„: {pet_name}
- ì¢…ë¥˜: {pet_species}
- ë‚˜ì´ ë‹¨ê³„: {pet_age_stage}
- ì²´ì¤‘: {pet_weight}kg
- í’ˆì¢…: {pet_breed}
- ì¤‘ì„±í™”: {pet_neutered}
- ê±´ê°• ê³ ë¯¼: {health_concerns}
- ì•Œë ˆë¥´ê¸°: {allergies}

ì¶”ì²œ ìƒí’ˆ:
- ë¸Œëœë“œ: {brand_name}
- ìƒí’ˆëª…: {product_name}

ì¶”ì²œ ì´ìœ  (ê¸°ìˆ ì ):
{technical_reasons}

ì‚¬ìš©ì ì„ í˜¸ë„:
{user_prefs_text}

{rag_context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ ì‚¬ë£Œê°€ ì™œ ì´ í«ì—ê²Œ ì¶”ì²œë˜ëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê³  ì¹œì ˆí•˜ê²Œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì¤˜.

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì„œ 3-5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì¤˜:
1. í«ì˜ ì´ë¦„ì„ ì‚¬ìš©í•´ì„œ ì¹œê·¼í•˜ê²Œ ì‹œì‘
2. í«ì˜ íŠ¹ì„±(ë‚˜ì´ ë‹¨ê³„, ê±´ê°• ê³ ë¯¼, ì•Œë ˆë¥´ê¸° ë“±)ê³¼ ì‚¬ë£Œì˜ ì—°ê²°ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ì£¼ìš” ì„±ë¶„ì´ë‚˜ íŠ¹ì§•ì´ í«ì—ê²Œ ì–´ë–¤ í˜œíƒì„ ì£¼ëŠ”ì§€ ìƒì„¸íˆ ì„¤ëª…
4. ì°¸ê³  ìë£Œ(rag_context)ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ê·¼ê±°ë¡œ ì „ë¬¸ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„¤ëª… ì¶”ê°€
5. ì‚¬ìš©ì ì„ í˜¸ë„ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë„ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰

ì„¤ëª…ì€ êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ë˜, ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³  ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•´ì¤˜."""


class RecommendationExplanationService:
    """ì¶”ì²œ ì´ìœ  ì„¤ëª… ìƒì„± ì„œë¹„ìŠ¤ (RAG ê¸°ë°˜)"""
    
    @staticmethod
    async def _retrieve_relevant_chunks(
        pet_species: str,
        health_concerns: List[str],
        allergies: List[str],
        product_name: str,
        top_k: int = 5
    ) -> List[Dict]:
        """
        Vector Storeì—ì„œ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰
        
        Returns:
            List[Dict]: ê° ì²­í¬ëŠ” {'content': str, 'source': str, 'metadata': dict} í˜•íƒœ
        """
        if not CHROMA_AVAILABLE:
            logger.warning("[RAG] âš ï¸ ChromaDBê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ RAG ê²€ìƒ‰ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            return []
        
        try:
            # Vector Store ê²½ë¡œ
            project_root = Path(__file__).parent.parent.parent
            vector_store_path = project_root / "data" / "vector_store"
            
            logger.info(f"[RAG] ğŸ” Vector Store ê²½ë¡œ í™•ì¸: {vector_store_path}")
            logger.info(f"[RAG] ğŸ” Vector Store ì¡´ì¬ ì—¬ë¶€: {vector_store_path.exists()}")
            
            if not vector_store_path.exists():
                logger.warning(f"[RAG] âš ï¸ Vector Storeê°€ ì—†ìŠµë‹ˆë‹¤: {vector_store_path}")
                return []
            
            # Chroma í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            client = chromadb.PersistentClient(path=str(vector_store_path))
            
            # ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜)
            metadata_corrupted = False
            
            try:
                logger.info("[RAG] ğŸ” ì»¬ë ‰ì…˜ 'pet_food_rag' ì¡°íšŒ ì‹œë„...")
                
                # list_collections()ëŠ” ë©”íƒ€ë°ì´í„° ì†ìƒ ì‹œ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì„ íƒì ìœ¼ë¡œ ì‹¤í–‰
                try:
                    collections = client.list_collections()
                    collection_names = [c.name for c in collections]
                    logger.info(f"[RAG] ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜: {collection_names}")
                    
                    if "pet_food_rag" not in collection_names:
                        logger.warning(f"[RAG] âš ï¸ ì»¬ë ‰ì…˜ 'pet_food_rag'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜: {collection_names}")
                        return []
                except KeyError as list_error:
                    # _type KeyErrorëŠ” ë©”íƒ€ë°ì´í„° ì†ìƒì„ ì˜ë¯¸
                    if "_type" in str(list_error):
                        metadata_corrupted = True
                        logger.warning(f"[RAG] âš ï¸ ChromaDB ë©”íƒ€ë°ì´í„° ì†ìƒ ê°ì§€ (list_collections ì‹¤íŒ¨). ì§ì ‘ ì¡°íšŒ ì‹œë„...")
                    else:
                        logger.warning(f"[RAG] âš ï¸ ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {type(list_error).__name__}: {str(list_error)}")
                except Exception as list_error:
                    # ê¸°íƒ€ ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ì§ì ‘ ì¡°íšŒ ì‹œë„
                    logger.debug(f"[RAG] ì»¬ë ‰ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ (ë¬´ì‹œ): {type(list_error).__name__}: {str(list_error)}")
                
                # ì§ì ‘ ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹œë„
                try:
                    collection = client.get_collection(name="pet_food_rag")
                    logger.info(f"[RAG] âœ… ì»¬ë ‰ì…˜ ì¡°íšŒ ì„±ê³µ: {collection.name}, ë¬¸ì„œ ìˆ˜: {collection.count()}")
                except KeyError as get_error:
                    # get_collection()ë„ _type ì—ëŸ¬ ë°œìƒ ì‹œ ë©”íƒ€ë°ì´í„° ì†ìƒìœ¼ë¡œ íŒë‹¨
                    if "_type" in str(get_error):
                        metadata_corrupted = True
                        raise  # ì™¸ë¶€ exceptë¡œ ì „ë‹¬
                    else:
                        raise
                        
            except KeyError as e:
                # _type KeyError ì²˜ë¦¬
                if "_type" in str(e) or metadata_corrupted:
                    logger.error(f"[RAG] âŒ ChromaDB ë©”íƒ€ë°ì´í„° ì†ìƒìœ¼ë¡œ ì»¬ë ‰ì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                               f"í•´ê²° ë°©ë²•: vector_store ë””ë ‰í† ë¦¬ ì‚­ì œ í›„ ì¬ìƒì„±í•˜ê±°ë‚˜ ChromaDBë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
                    return []
                else:
                    logger.warning(f"[RAG] âš ï¸ ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {type(e).__name__}: {str(e)}")
                    return []
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                
                # ChromaDBì˜ íŠ¹ì • ì—ëŸ¬ íƒ€ì… í™•ì¸
                if error_type == "InvalidCollectionException" or "does not exist" in error_msg.lower():
                    logger.warning(f"[RAG] âš ï¸ ì»¬ë ‰ì…˜ 'pet_food_rag'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    logger.warning(f"[RAG] âš ï¸ ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {error_type}: {error_msg}")
                
                return []
            
            # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
            query_parts = []
            if pet_species:
                query_parts.append(f"{pet_species} ì‚¬ë£Œ")
            if health_concerns:
                query_parts.extend(health_concerns)
            if allergies:
                query_parts.extend([f"{allergy} ì•Œë ˆë¥´ê¸°" for allergy in allergies])
            if product_name:
                query_parts.append(product_name)
            
            query_text = " ".join(query_parts) if query_parts else product_name or "ë°˜ë ¤ë™ë¬¼ ì‚¬ë£Œ"
            
            logger.info(f"[RAG] ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query_text}")
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            openai_client = get_openai_client()
            query_response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=query_text
            )
            query_embedding = query_response.data[0].embedding
            
            # Vector Storeì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            logger.info(f"[RAG] ğŸ” Vector Store ê²€ìƒ‰ ì‹œì‘: top_k={top_k}")
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=["documents", "metadatas", "distances"]
            )
            logger.info(f"[RAG] ğŸ” ê²€ìƒ‰ ê²°ê³¼: ids={len(results.get('ids', [[]])[0]) if results.get('ids') else 0}ê°œ")
            
            # ê²°ê³¼ ë³€í™˜
            chunks = []
            if results["ids"] and len(results["ids"][0]) > 0:
                for idx, doc_id in enumerate(results["ids"][0]):
                    chunk = {
                        "content": results["documents"][0][idx],
                        "source": results["metadatas"][0][idx].get("source", "Unknown"),
                        "file": results["metadatas"][0][idx].get("file", "Unknown"),
                        "distance": results["distances"][0][idx],
                        "metadata": results["metadatas"][0][idx]
                    }
                    chunks.append(chunk)
                
                logger.info(f"[RAG] âœ… {len(chunks)}ê°œ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰ ì™„ë£Œ")
                
                # RAG ë°˜í™˜ê°’ ìƒì„¸ ë¡œê·¸ ì¶œë ¥
                logger.info("=" * 80)
                logger.info("[RAG] ğŸ“‹ RAG ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸:")
                logger.info("=" * 80)
                for idx, chunk in enumerate(chunks, 1):
                    logger.info(f"\n[ì²­í¬ {idx}/{len(chunks)}]")
                    logger.info(f"  ğŸ“„ ì¶œì²˜ (Source): {chunk.get('source', 'Unknown')}")
                    logger.info(f"  ğŸ“ íŒŒì¼ (File): {chunk.get('file', 'Unknown')}")
                    logger.info(f"  ğŸ“ ìœ ì‚¬ë„ ê±°ë¦¬ (Distance): {chunk.get('distance', 0.0):.4f}")
                    content = chunk.get('content', '')
                    logger.info(f"  ğŸ“ ë‚´ìš© ê¸¸ì´: {len(content)}ì")
                    logger.info(f"  ğŸ“ ë‚´ìš© (Content) - ì „ì²´:")
                    logger.info(f"  {'-' * 76}")
                    # ì „ì²´ ë‚´ìš©ì„ ì—¬ëŸ¬ ì¤„ë¡œ ì¶œë ¥ (ê¸´ í…ìŠ¤íŠ¸ë„ ëª¨ë‘ ì¶œë ¥)
                    for line in content.split('\n'):
                        logger.info(f"  {line}")
                    logger.info(f"  {'-' * 76}")
                    logger.info(f"  ğŸ·ï¸  ë©”íƒ€ë°ì´í„°: {chunk.get('metadata', {})}")
                logger.info("=" * 80)
            else:
                logger.warning("[RAG] âš ï¸ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            return chunks
            
        except Exception as e:
            logger.error(f"[RAG] ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            return []
    
    @staticmethod
    def _calculate_confidence_score(
        explanation: str,
        retrieved_chunks: List[Dict],
        llm_response_metadata: Optional[Dict] = None
    ) -> float:
        """
        RAG ê¸°ë°˜ ì„¤ëª…ì˜ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0~100)
        
        Args:
            explanation: ìƒì„±ëœ ì„¤ëª…
            retrieved_chunks: ê²€ìƒ‰ëœ ë¬¸ì„œ ì²­í¬
            llm_response_metadata: LLM ì‘ë‹µ ë©”íƒ€ë°ì´í„° (logprobs ë“±)
        
        Returns:
            float: ì‹ ë¢°ë„ ì ìˆ˜ (0~100)
        """
        if not explanation:
            return 0.0
        
        # RAG ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë‚®ì€ ì‹ ë¢°ë„
        if not retrieved_chunks:
            return 50.0
        
        # ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        # Chromaì˜ distanceëŠ” ì‘ì„ìˆ˜ë¡ ìœ ì‚¬í•¨ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
        # distanceë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜: distanceê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
        distances = [chunk.get("distance", 1.0) for chunk in retrieved_chunks]
        avg_distance = sum(distances) / len(distances) if distances else 1.0
        
        # distanceë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜ (0.0 ~ 1.0 ë²”ìœ„ë¥¼ 50 ~ 100 ì ìˆ˜ë¡œ ë³€í™˜)
        # distanceê°€ 0.5 ì´í•˜ë©´ ë†’ì€ ì‹ ë¢°ë„ (80~100)
        # distanceê°€ 0.5~1.0ì´ë©´ ì¤‘ê°„ ì‹ ë¢°ë„ (60~80)
        # distanceê°€ 1.0 ì´ìƒì´ë©´ ë‚®ì€ ì‹ ë¢°ë„ (50~60)
        if avg_distance <= 0.5:
            confidence = 80.0 + (0.5 - avg_distance) * 40.0  # 80~100
        elif avg_distance <= 1.0:
            confidence = 60.0 + (1.0 - avg_distance) * 40.0  # 60~80
        else:
            confidence = 50.0 + max(0, 10.0 - (avg_distance - 1.0) * 10.0)  # 50~60
        
        return min(100.0, max(0.0, confidence))
    
    @staticmethod
    async def generate_technical_explanation(
        pet_name: str,
        pet_species: str,
        pet_age_stage: Optional[str],
        pet_weight: float,
        pet_breed: Optional[str],
        pet_neutered: Optional[bool],
        health_concerns: List[str],
        allergies: List[str],
        brand_name: str,
        product_name: str,
        technical_reasons: List[str],
        user_prefs: dict = None
    ) -> str:
        """
        ê¸°ìˆ ì  ì¶”ì²œ ì´ìœ  ê¸°ë°˜ ì„¤ëª… ìƒì„± (RAG ì—†ìŒ, ë¹ ë¦„)
        
        Args:
            pet_name: í« ì´ë¦„
            pet_species: í« ì¢…ë¥˜ (DOG/CAT)
            pet_age_stage: ë‚˜ì´ ë‹¨ê³„ (PUPPY/ADULT/SENIOR)
            pet_weight: ì²´ì¤‘ (kg)
            pet_breed: í’ˆì¢… ì½”ë“œ
            pet_neutered: ì¤‘ì„±í™” ì—¬ë¶€
            health_concerns: ê±´ê°• ê³ ë¯¼ ë¦¬ìŠ¤íŠ¸
            allergies: ì•Œë ˆë¥´ê¸° ë¦¬ìŠ¤íŠ¸
            brand_name: ë¸Œëœë“œëª…
            product_name: ìƒí’ˆëª…
            technical_reasons: ê¸°ìˆ ì  ì¶”ì²œ ì´ìœ  ë¦¬ìŠ¤íŠ¸
            user_prefs: ì‚¬ìš©ì ì„ í˜¸ë„
        
        Returns:
            ìì—°ì–´ ì„¤ëª… ë¬¸ìì—´
        """
        try:
            logger.info(f"[Explanation Service] ğŸ”§ ê¸°ìˆ ì  ì„¤ëª… ìƒì„± ì‹œì‘: {pet_name} - {brand_name} {product_name}")
            
            # ê¸°ìˆ ì  ì´ìœ ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            reasons_text = "\n".join([f"- {reason}" for reason in technical_reasons])
            
            # ë‚˜ì´ ë‹¨ê³„ í•œê¸€ ë³€í™˜
            age_stage_kr = {
                "PUPPY": "ê°•ì•„ì§€",
                "ADULT": "ì„±ê²¬",
                "SENIOR": "ë…¸ê²¬"
            }.get(pet_age_stage or "", "ì„±ê²¬")
            
            # ì¢…ë¥˜ í•œê¸€ ë³€í™˜
            species_kr = "ê°•ì•„ì§€" if pet_species == "DOG" else "ê³ ì–‘ì´"
            
            # ì¤‘ì„±í™” ì—¬ë¶€ í…ìŠ¤íŠ¸
            neutered_text = "ì™„ë£Œ" if pet_neutered else "ë¯¸ì™„ë£Œ" if pet_neutered is False else "ëª¨ë¦„"
            
            # ê±´ê°• ê³ ë¯¼ í…ìŠ¤íŠ¸
            health_concerns_text = ", ".join(health_concerns) if health_concerns else "ì—†ìŒ"
            
            # ì•Œë ˆë¥´ê¸° í…ìŠ¤íŠ¸
            allergies_text = ", ".join(allergies) if allergies else "ì—†ìŒ"
            
            # í’ˆì¢… í…ìŠ¤íŠ¸
            breed_text = pet_breed or "ì •ë³´ ì—†ìŒ"
            
            # ì‚¬ìš©ì ì„ í˜¸ë„ í…ìŠ¤íŠ¸ ìƒì„±
            user_prefs_text = "ì—†ìŒ"
            if user_prefs:
                weights_preset = user_prefs.get("weights_preset", "BALANCED")
                hard_exclude = user_prefs.get("hard_exclude_allergens", [])
                soft_avoid = user_prefs.get("soft_avoid_ingredients", [])
                max_price = user_prefs.get("max_price_per_kg")
                
                preset_kr = {
                    "SAFE": "ì•ˆì „ ìš°ì„ ",
                    "BALANCED": "ê· í˜•",
                    "VALUE": "ê°€ì„±ë¹„ ìš°ì„ "
                }.get(weights_preset, weights_preset)
                
                prefs_parts = [f"ëª¨ë“œ: {preset_kr}"]
                if hard_exclude:
                    prefs_parts.append(f"ì œì™¸ ì•Œë ˆë¥´ê²: {', '.join(hard_exclude)}")
                if soft_avoid:
                    prefs_parts.append(f"í”¼í•˜ê³  ì‹¶ì€ ì„±ë¶„: {', '.join(soft_avoid)}")
                if max_price:
                    prefs_parts.append(f"ìµœëŒ€ ê°€ê²©: {max_price}ì›/kg")
                
                user_prefs_text = ", ".join(prefs_parts) if prefs_parts else "ì—†ìŒ"
            
            prompt = USER_PROMPT_TEMPLATE_TECHNICAL.format(
                pet_name=pet_name,
                pet_species=species_kr,
                pet_age_stage=age_stage_kr,
                pet_weight=pet_weight,
                pet_breed=breed_text,
                pet_neutered=neutered_text,
                health_concerns=health_concerns_text,
                allergies=allergies_text,
                brand_name=brand_name,
                product_name=product_name,
                technical_reasons=reasons_text,
                user_prefs_text=user_prefs_text
            )
            
            client = get_openai_client()
            
            response = client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                temperature=0.7,
                max_tokens=250,  # ê¸°ìˆ ì  ì„¤ëª…ì€ ë” ì§§ê²Œ
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_TECHNICAL},
                    {"role": "user", "content": prompt},
                ],
            )
            
            explanation = response.choices[0].message.content.strip()
            logger.info(f"[Explanation Service] âœ… ê¸°ìˆ ì  ì„¤ëª… ìƒì„± ì™„ë£Œ: {explanation[:50]}...")
            
            return explanation
            
        except Exception as e:
            logger.error(f"[Explanation Service] ê¸°ìˆ ì  ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª… ë°˜í™˜
            return RecommendationExplanationService._generate_fallback_explanation(
                pet_name, technical_reasons
            )
    
    @staticmethod
    async def generate_expert_explanation(
        pet_name: str,
        pet_species: str,
        pet_age_stage: Optional[str],
        pet_weight: float,
        pet_breed: Optional[str],
        pet_neutered: Optional[bool],
        health_concerns: List[str],
        allergies: List[str],
        brand_name: str,
        product_name: str,
        technical_reasons: List[str],
        user_prefs: dict = None
    ) -> str:
        """
        RAG ê¸°ë°˜ ì „ë¬¸ê°€ ìˆ˜ì¤€ ì„¤ëª… ìƒì„± (ëŠë¦¼)
        
        Args:
            pet_name: í« ì´ë¦„
            pet_species: í« ì¢…ë¥˜ (DOG/CAT)
            pet_age_stage: ë‚˜ì´ ë‹¨ê³„ (PUPPY/ADULT/SENIOR)
            pet_weight: ì²´ì¤‘ (kg)
            pet_breed: í’ˆì¢… ì½”ë“œ
            pet_neutered: ì¤‘ì„±í™” ì—¬ë¶€
            health_concerns: ê±´ê°• ê³ ë¯¼ ë¦¬ìŠ¤íŠ¸
            allergies: ì•Œë ˆë¥´ê¸° ë¦¬ìŠ¤íŠ¸
            brand_name: ë¸Œëœë“œëª…
            product_name: ìƒí’ˆëª…
            technical_reasons: ê¸°ìˆ ì  ì¶”ì²œ ì´ìœ  ë¦¬ìŠ¤íŠ¸
            user_prefs: ì‚¬ìš©ì ì„ í˜¸ë„
        
        Returns:
            ìì—°ì–´ ì„¤ëª… ë¬¸ìì—´
        """
        try:
            # RAG: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            logger.info("=" * 80)
            logger.info(f"[RAG] ğŸ¯ RAG ì‹¤í–‰ ì‹œì‘: pet_species={pet_species}, product={product_name}")
            logger.info(f"[RAG] ğŸ“‹ ì…ë ¥ íŒŒë¼ë¯¸í„°: health_concerns={health_concerns}, allergies={allergies}")
            logger.info("=" * 80)
            retrieved_chunks = await RecommendationExplanationService._retrieve_relevant_chunks(
                pet_species=pet_species,
                health_concerns=health_concerns,
                allergies=allergies,
                product_name=product_name,
                top_k=5
            )
            logger.info(f"[RAG] âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(retrieved_chunks)}ê°œ ë¬¸ì„œ ì²­í¬ ë°œê²¬")
            
            # RAG ë°˜í™˜ê°’ ì „ì²´ ë¡œê·¸ ì¶œë ¥
            if retrieved_chunks:
                logger.info("\n" + "=" * 80)
                logger.info("[RAG] ğŸ“Š ì „ë¬¸ê°€ ì„¤ëª… ìƒì„±ì—ì„œ ë°›ì€ RAG ê²°ê³¼ ì „ì²´:")
                logger.info("=" * 80)
                for idx, chunk in enumerate(retrieved_chunks, 1):
                    logger.info(f"\n[ì²­í¬ {idx}/{len(retrieved_chunks)}]")
                    logger.info(f"  ì¶œì²˜: {chunk.get('source', 'Unknown')}")
                    logger.info(f"  íŒŒì¼: {chunk.get('file', 'Unknown')}")
                    logger.info(f"  ê±°ë¦¬: {chunk.get('distance', 0.0):.4f}")
                    content = chunk.get('content', '')
                    logger.info(f"  ë‚´ìš© ê¸¸ì´: {len(content)}ì")
                    logger.info(f"  ë‚´ìš© (Content) - ì „ì²´:")
                    logger.info(f"  {'-' * 76}")
                    # ì „ì²´ ë‚´ìš©ì„ ì—¬ëŸ¬ ì¤„ë¡œ ì¶œë ¥
                    for line in content.split('\n'):
                        logger.info(f"  {line}")
                    logger.info(f"  {'-' * 76}")
                    logger.info(f"  ë©”íƒ€ë°ì´í„°: {chunk.get('metadata', {})}")
                logger.info("=" * 80 + "\n")
            
            # RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            rag_context = ""
            if retrieved_chunks:
                rag_context = "\nì°¸ê³  ìë£Œ (ì „ë¬¸ ë¬¸ì„œ):\n"
                for idx, chunk in enumerate(retrieved_chunks[:5], 1):
                    source = chunk.get("source", "Unknown")
                    content = chunk.get("content", "")[:500]  # í”„ë¡¬í”„íŠ¸ì—ëŠ” 500ìë§Œ ì‚¬ìš©
                    distance = chunk.get("distance", 0.0)
                    rag_context += f"{idx}. [{source}] (ìœ ì‚¬ë„: {1-distance:.2f})\n{content}\n\n"
                
                # RAG ì»¨í…ìŠ¤íŠ¸ ì „ì²´ ë¡œê·¸ ì¶œë ¥
                logger.info("[RAG] ğŸ“„ LLMì— ì „ë‹¬ë  RAG ì»¨í…ìŠ¤íŠ¸:")
                logger.info("=" * 80)
                logger.info(rag_context)
                logger.info("=" * 80)
            else:
                rag_context = "\nì°¸ê³  ìë£Œ: ì—†ìŒ\n"
                logger.info("[RAG] âš ï¸ RAG ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (retrieved_chunksê°€ ë¹„ì–´ìˆìŒ)")
            
            # ê¸°ìˆ ì  ì´ìœ ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            reasons_text = "\n".join([f"- {reason}" for reason in technical_reasons])
            
            # ë‚˜ì´ ë‹¨ê³„ í•œê¸€ ë³€í™˜
            age_stage_kr = {
                "PUPPY": "ê°•ì•„ì§€",
                "ADULT": "ì„±ê²¬",
                "SENIOR": "ë…¸ê²¬"
            }.get(pet_age_stage or "", "ì„±ê²¬")
            
            # ì¢…ë¥˜ í•œê¸€ ë³€í™˜
            species_kr = "ê°•ì•„ì§€" if pet_species == "DOG" else "ê³ ì–‘ì´"
            
            # ì¤‘ì„±í™” ì—¬ë¶€ í…ìŠ¤íŠ¸
            neutered_text = "ì™„ë£Œ" if pet_neutered else "ë¯¸ì™„ë£Œ" if pet_neutered is False else "ëª¨ë¦„"
            
            # ê±´ê°• ê³ ë¯¼ í…ìŠ¤íŠ¸
            health_concerns_text = ", ".join(health_concerns) if health_concerns else "ì—†ìŒ"
            
            # ì•Œë ˆë¥´ê¸° í…ìŠ¤íŠ¸
            allergies_text = ", ".join(allergies) if allergies else "ì—†ìŒ"
            
            # í’ˆì¢… í…ìŠ¤íŠ¸
            breed_text = pet_breed or "ì •ë³´ ì—†ìŒ"
            
            # ì‚¬ìš©ì ì„ í˜¸ë„ í…ìŠ¤íŠ¸ ìƒì„±
            user_prefs_text = "ì—†ìŒ"
            if user_prefs:
                weights_preset = user_prefs.get("weights_preset", "BALANCED")
                hard_exclude = user_prefs.get("hard_exclude_allergens", [])
                soft_avoid = user_prefs.get("soft_avoid_ingredients", [])
                max_price = user_prefs.get("max_price_per_kg")
                
                preset_kr = {
                    "SAFE": "ì•ˆì „ ìš°ì„ ",
                    "BALANCED": "ê· í˜•",
                    "VALUE": "ê°€ì„±ë¹„ ìš°ì„ "
                }.get(weights_preset, weights_preset)
                
                prefs_parts = [f"ëª¨ë“œ: {preset_kr}"]
                if hard_exclude:
                    prefs_parts.append(f"ì œì™¸ ì•Œë ˆë¥´ê²: {', '.join(hard_exclude)}")
                if soft_avoid:
                    prefs_parts.append(f"í”¼í•˜ê³  ì‹¶ì€ ì„±ë¶„: {', '.join(soft_avoid)}")
                if max_price:
                    prefs_parts.append(f"ìµœëŒ€ ê°€ê²©: {max_price}ì›/kg")
                
                user_prefs_text = ", ".join(prefs_parts) if prefs_parts else "ì—†ìŒ"
            
            prompt = USER_PROMPT_TEMPLATE_EXPERT.format(
                pet_name=pet_name,
                pet_species=species_kr,
                pet_age_stage=age_stage_kr,
                pet_weight=pet_weight,
                pet_breed=breed_text,
                pet_neutered=neutered_text,
                health_concerns=health_concerns_text,
                allergies=allergies_text,
                brand_name=brand_name,
                product_name=product_name,
                technical_reasons=reasons_text,
                user_prefs_text=user_prefs_text,
                rag_context=rag_context
            )
            
            # ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì „ì²´ ë¡œê·¸ ì¶œë ¥
            logger.info("[Explanation Service] ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì „ì²´:")
            logger.info("=" * 80)
            logger.info(f"System Prompt:\n{SYSTEM_PROMPT_EXPERT}")
            logger.info("-" * 80)
            logger.info(f"User Prompt:\n{prompt}")
            logger.info("=" * 80)
            
            client = get_openai_client()
            
            logger.info(f"[Explanation Service] ğŸ“ ì „ë¬¸ê°€ ì„¤ëª… ìƒì„± ì‹œì‘: {pet_name} - {brand_name} {product_name}")
            
            response = client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                temperature=0.7,
                max_tokens=400,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT_EXPERT},
                    {"role": "user", "content": prompt},
                ],
            )
            
            explanation = response.choices[0].message.content.strip()
            
            # LLM ì‘ë‹µ ì „ì²´ ë¡œê·¸ ì¶œë ¥
            logger.info("[Explanation Service] ğŸ¤– LLM ì‘ë‹µ ì „ì²´:")
            logger.info("=" * 80)
            logger.info(explanation)
            logger.info("=" * 80)
            logger.info(f"ì‘ë‹µ ê¸¸ì´: {len(explanation)}ì")
            
            # Confidence Score ê³„ì‚°
            confidence_score = RecommendationExplanationService._calculate_confidence_score(
                explanation=explanation,
                retrieved_chunks=retrieved_chunks
            )
            
            logger.info(f"[Explanation Service] âœ… ì „ë¬¸ê°€ ì„¤ëª… ìƒì„± ì™„ë£Œ: {explanation[:50]}... (ì‹ ë¢°ë„: {confidence_score:.1f}ì )")
            
            # ì‹ ë¢°ë„ê°€ 75ì  ë¯¸ë§Œì´ë©´ fallback ë©”ì‹œì§€ ì‚¬ìš©
            if confidence_score < 75.0:
                logger.warning(f"[Explanation Service] ì‹ ë¢°ë„ê°€ ë‚®ì•„ fallback ë©”ì‹œì§€ ì‚¬ìš©: {confidence_score:.1f}ì ")
                return RecommendationExplanationService._generate_fallback_explanation(
                    pet_name, technical_reasons
                )
            
            return explanation
            
        except Exception as e:
            logger.error(f"[Explanation Service] ì „ë¬¸ê°€ ì„¤ëª… ìƒì„± ì‹¤íŒ¨: {str(e)}", exc_info=True)
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª… ë°˜í™˜
            return RecommendationExplanationService._generate_fallback_explanation(
                pet_name, technical_reasons
            )
    
    @staticmethod
    async def generate_explanation(
        pet_name: str,
        pet_species: str,
        pet_age_stage: Optional[str],
        pet_weight: float,
        pet_breed: Optional[str],
        pet_neutered: Optional[bool],
        health_concerns: List[str],
        allergies: List[str],
        brand_name: str,
        product_name: str,
        technical_reasons: List[str],
        user_prefs: dict = None
    ) -> str:
        """
        [Deprecated] í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€
        ì „ë¬¸ê°€ ì„¤ëª…(expert_explanation)ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        logger.warning("[Explanation Service] generate_explanationì€ deprecatedì…ë‹ˆë‹¤. generate_expert_explanationì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return await RecommendationExplanationService.generate_expert_explanation(
            pet_name=pet_name,
            pet_species=pet_species,
            pet_age_stage=pet_age_stage,
            pet_weight=pet_weight,
            pet_breed=pet_breed,
            pet_neutered=pet_neutered,
            health_concerns=health_concerns,
            allergies=allergies,
            brand_name=brand_name,
            product_name=product_name,
            technical_reasons=technical_reasons,
            user_prefs=user_prefs
        )
    
    @staticmethod
    def _generate_fallback_explanation(pet_name: str, technical_reasons: List[str]) -> str:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì„¤ëª… ìƒì„±"""
        if not technical_reasons:
            return f"{pet_name}ì—ê²Œ ì í•©í•œ ì‚¬ë£Œì…ë‹ˆë‹¤."
        
        # ì£¼ìš” ì´ìœ ë§Œ ì„ íƒ (ìµœëŒ€ 3ê°œ)
        main_reasons = technical_reasons[:3]
        reasons_text = ", ".join(main_reasons)
        
        return f"{pet_name}ì—ê²Œ {reasons_text} ë“±ì˜ ì´ìœ ë¡œ ì¶”ì²œë˜ëŠ” ì‚¬ë£Œì…ë‹ˆë‹¤."
